{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6607339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/riadanas/Desktop/MLE Diary of a CEO/data/raw/Esu8BXLBmZ4_comments.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346ecf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ad723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "      <th>view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>comment_like_count</th>\n",
       "      <th>comment_published_at</th>\n",
       "      <th>is_pinned</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>parent_comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Diary Of A CEO</td>\n",
       "      <td>UCGq-a57w-aPwyi3pW7XLiHw</td>\n",
       "      <td>Esu8BXLBmZ4</td>\n",
       "      <td>Atheist vs Christian vs Spiritual Thinker: The...</td>\n",
       "      <td>2025-09-29T07:00:15Z</td>\n",
       "      <td>58227</td>\n",
       "      <td>3338</td>\n",
       "      <td>UgwK5fuPVdGdnrRuUbB4AaABAg.ANdq3qa6jmIANdqhoWY4_e</td>\n",
       "      <td>I like this format much better than the other ...</td>\n",
       "      <td>@JoelJose12345</td>\n",
       "      <td>UClXaG5i-lnqXbUMb6ayjTRQ</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-09-29T07:08:06Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwK5fuPVdGdnrRuUbB4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Diary Of A CEO</td>\n",
       "      <td>UCGq-a57w-aPwyi3pW7XLiHw</td>\n",
       "      <td>Esu8BXLBmZ4</td>\n",
       "      <td>Atheist vs Christian vs Spiritual Thinker: The...</td>\n",
       "      <td>2025-09-29T07:00:15Z</td>\n",
       "      <td>58227</td>\n",
       "      <td>3338</td>\n",
       "      <td>UgwK5fuPVdGdnrRuUbB4AaABAg.ANdq3qa6jmIANds81ZbBzD</td>\n",
       "      <td>Yeah, this format is great. Except that one ti...</td>\n",
       "      <td>@Little_Shadow_</td>\n",
       "      <td>UCVLRgNZlbI04EE-ssMhgaiA</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-29T07:20:34Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>UgwK5fuPVdGdnrRuUbB4AaABAg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         channel_name                channel_id     video_id  \\\n",
       "0  The Diary Of A CEO  UCGq-a57w-aPwyi3pW7XLiHw  Esu8BXLBmZ4   \n",
       "1  The Diary Of A CEO  UCGq-a57w-aPwyi3pW7XLiHw  Esu8BXLBmZ4   \n",
       "\n",
       "                                         video_title    video_published_at  \\\n",
       "0  Atheist vs Christian vs Spiritual Thinker: The...  2025-09-29T07:00:15Z   \n",
       "1  Atheist vs Christian vs Spiritual Thinker: The...  2025-09-29T07:00:15Z   \n",
       "\n",
       "   view_count  video_like_count  \\\n",
       "0       58227              3338   \n",
       "1       58227              3338   \n",
       "\n",
       "                                          comment_id  \\\n",
       "0  UgwK5fuPVdGdnrRuUbB4AaABAg.ANdq3qa6jmIANdqhoWY4_e   \n",
       "1  UgwK5fuPVdGdnrRuUbB4AaABAg.ANdq3qa6jmIANds81ZbBzD   \n",
       "\n",
       "                                        comment_text           author  \\\n",
       "0  I like this format much better than the other ...   @JoelJose12345   \n",
       "1  Yeah, this format is great. Except that one ti...  @Little_Shadow_   \n",
       "\n",
       "                  author_id  comment_like_count  comment_published_at  \\\n",
       "0  UClXaG5i-lnqXbUMb6ayjTRQ                   6  2025-09-29T07:08:06Z   \n",
       "1  UCVLRgNZlbI04EE-ssMhgaiA                   4  2025-09-29T07:20:34Z   \n",
       "\n",
       "   is_pinned  is_reply           parent_comment_id  \n",
       "0      False      True  UgwK5fuPVdGdnrRuUbB4AaABAg  \n",
       "1      False      True  UgwK5fuPVdGdnrRuUbB4AaABAg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27237f5",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab8a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1. Text Cleaning (light only)\n",
    "# ------------------------------------------------------\n",
    "def clean_comment(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Light cleaning for comments:\n",
    "    - Remove @mentions\n",
    "    - Remove URLs\n",
    "    - Remove emojis / non-ascii\n",
    "    - Lowercase\n",
    "    - Strip whitespace\n",
    "    - Keep context words (no lemmatization, no stopword removal yet)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # remove mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "    # remove emojis/non-ascii\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "    # lowercase + strip\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cb8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like this format much better than the other ...</td>\n",
       "      <td>i like this format much better than the other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, this format is great. Except that one ti...</td>\n",
       "      <td>yeah, this format is great. except that one ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes Praise Jesus Christ!</td>\n",
       "      <td>yes praise jesus christ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@Little_Shadow_ Which episode was that one pl...</td>\n",
       "      <td>@ which episode was that one please?!?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bro you should have invited a Muslim like Musl...</td>\n",
       "      <td>bro you should have invited a muslim like musl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üíõüíõüëä</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I like the format but man‚Ä¶ while I usually dig...</td>\n",
       "      <td>i like the format but man while i usually dig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I really want a conversation with Esther Perel...</td>\n",
       "      <td>i really want a conversation with esther perel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You need to have Britt Hartley on</td>\n",
       "      <td>you need to have britt hartley on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Invite Omar Suleiman from Yaqeen Institute, he...</td>\n",
       "      <td>invite omar suleiman from yaqeen institute, he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  I like this format much better than the other ...   \n",
       "1  Yeah, this format is great. Except that one ti...   \n",
       "2                           Yes Praise Jesus Christ!   \n",
       "3  @@Little_Shadow_ Which episode was that one pl...   \n",
       "4  Bro you should have invited a Muslim like Musl...   \n",
       "5                                                üíõüíõüëä   \n",
       "6  I like the format but man‚Ä¶ while I usually dig...   \n",
       "7  I really want a conversation with Esther Perel...   \n",
       "8                  You need to have Britt Hartley on   \n",
       "9  Invite Omar Suleiman from Yaqeen Institute, he...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  i like this format much better than the other ...  \n",
       "1  yeah, this format is great. except that one ti...  \n",
       "2                           yes praise jesus christ!  \n",
       "3             @ which episode was that one please?!?  \n",
       "4  bro you should have invited a muslim like musl...  \n",
       "5                                                     \n",
       "6  i like the format but man while i usually dig ...  \n",
       "7  i really want a conversation with esther perel...  \n",
       "8                  you need to have britt hartley on  \n",
       "9  invite omar suleiman from yaqeen institute, he...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply light cleaning to the comment_text column\n",
    "df[\"cleaned_text\"] = df[\"comment_text\"].apply(clean_comment)\n",
    "\n",
    "# Preview the results\n",
    "df[[\"comment_text\", \"cleaned_text\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f129b61",
   "metadata": {},
   "source": [
    "## Topic category (llama) -> Once per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04cbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def get_topic_category(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Use Ollama to classify the video title into a topic category.\n",
    "    Example categories: health, mental health, productivity, finance, relationships, entrepreneurship, other.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Categorize the following YouTube video title into ONE broad category:\n",
    "    - health\n",
    "    - mental health\n",
    "    - productivity\n",
    "    - finance\n",
    "    - relationships\n",
    "    - entrepreneurship\n",
    "    - Religion / Spirituality\n",
    "    - Technology\n",
    "    - Education\n",
    "    - Lifestyle\n",
    "    - Entertainment\n",
    "    - other\n",
    "\n",
    "    Title: \"{title}\"\n",
    "\n",
    "    Return only the category name, nothing else.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2:3b\",  # you can swap to another local model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a391d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Extract unique video_id/title pairs\n",
    "video_meta = df[[\"video_id\", \"video_title\"]].drop_duplicates()\n",
    "\n",
    "# Apply Ollama category classification\n",
    "video_meta[\"Topic_Category\"] = video_meta[\"video_title\"].apply(get_topic_category)\n",
    "\n",
    "# Merge back into main dataframe\n",
    "df = df.merge(video_meta[[\"video_id\", \"Topic_Category\"]], on=\"video_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f90aac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic_Category\n",
       "religion / spirituality    1296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Topic_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2b696",
   "metadata": {},
   "source": [
    "## Sentiment analysis (Gemma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb74efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Helpers & resources\n",
    "# -----------------------------\n",
    "NEG_PHRASES = [\n",
    "    r\"\\bnot good\\b\", r\"\\bnot great\\b\", r\"\\bnot helpful\\b\", r\"\\bdon't like\\b\", r\"\\bdont like\\b\",\n",
    "    r\"\\bnot worth\\b\", r\"\\bwaste of time\\b\", r\"\\btoo long\\b\", r\"\\btoo slow\\b\", r\"\\btoo loud\\b\",\n",
    "    r\"\\bmisleading\\b\", r\"\\bclickbait\\b\", r\"\\bbiased\\b\", r\"\\bconfusing\\b\", r\"\\bannoying\\b\",\n",
    "    r\"\\bcringe\\b\", r\"\\bstupid\\b\", r\"\\bdumb\\b\", r\"\\bbad\\b\", r\"\\bawful\\b\", r\"\\bterrible\\b\",\n",
    "    r\"\\buseless\\b\", r\"\\bpointless\\b\", r\"\\bwrong\\b\", r\"\\bpoor (audio|sound|quality)\\b\",\n",
    "    r\"\\birrelevant\\b\", r\"\\boff\\-topic\\b\", r\"\\bproblem\\b\", r\"\\bissue\\b\", r\"\\bdisappoint(ing|ed)\\b\",\n",
    "    r\"\\brude\\b\", r\"\\boffensive\\b\", r\"\\bunfunny\\b\", r\"\\bboring\\b\", r\"\\blazy\\b\", r\"\\btoxic\\b\",\n",
    "    r\"\\bhate\\b\", r\"\\bgarbage\\b\", r\"\\bignorant\\b\", r\"\\bweird\\b\", r\"\\bnegative\\b\", r\"\\bbroken\\b\",\n",
    "    r\"\\bdownvote\\b\", r\"\\bterribly\\b\", r\"\\bdislike\\b\", r\"\\bpathetic\\b\", r\"\\bworse\\b\"\n",
    "]\n",
    "NEG_RE = re.compile(\"|\".join(NEG_PHRASES))\n",
    "\n",
    "SHORT_PRAISE_RE = re.compile(r\"^(nice|cool|great|good|amazing|awesome|wow|love|thanks|perfect)[.!]?$\", re.I)\n",
    "\n",
    "# Load spaCy (light model for entity recognition)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"lemmatizer\"])\n",
    "\n",
    "def clean_comment(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def bucket_from_p(p: float) -> str:\n",
    "    if p < 0.35:\n",
    "        return \"Negative\"\n",
    "    if p > 0.65:\n",
    "        return \"Positive\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) HF Sentiment (RoBERTa)\n",
    "# -----------------------------\n",
    "_HF_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "_tok = AutoTokenizer.from_pretrained(_HF_MODEL)\n",
    "_model = AutoModelForSequenceClassification.from_pretrained(_HF_MODEL)\n",
    "_model.eval()\n",
    "\n",
    "def roberta_probs(text: str) -> dict:\n",
    "    if not text:\n",
    "        return {\"neg\": 0.0, \"neu\": 1.0, \"pos\": 0.0}\n",
    "    with torch.no_grad():\n",
    "        inputs = _tok(text[:512], return_tensors=\"pt\")\n",
    "        logits = _model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    return {\"neg\": float(probs[0]), \"neu\": float(probs[1]), \"pos\": float(probs[2])}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) LLM Sentiment (Gemma 2B)\n",
    "# -----------------------------\n",
    "def gemma_score_01(text: str) -> float:\n",
    "    if not text:\n",
    "        return 0.5\n",
    "    prompt = f\"\"\"\n",
    "    You are a neutral linguistic expert analyzing sentiment.\n",
    "    Evaluate only the tone of the YouTube comment.\n",
    "    Consider sarcasm and negation carefully.\n",
    "    Return JSON only: {{\"score\": <float between -1.0 and 1.0>}}\n",
    "    Comment: \"{text}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = ollama.chat(model=\"gemma:2b\", messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "        j = json.loads(resp[\"message\"][\"content\"])\n",
    "        s = float(j.get(\"score\", 0.0))\n",
    "    except Exception:\n",
    "        s = 0.0\n",
    "\n",
    "    p = (s + 1.0) / 2.0\n",
    "    if NEG_RE.search(text) and p > 0.5:\n",
    "        p -= 0.25\n",
    "    if SHORT_PRAISE_RE.match(text) and p > 0.7:\n",
    "        p = 0.6\n",
    "    return float(np.clip(p, 0.0, 1.0))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Ensemble Sentiment\n",
    "# -----------------------------\n",
    "def ensemble_sentiment(text: str) -> dict:\n",
    "    text_clean = clean_comment(text.lower())\n",
    "    if not text_clean:\n",
    "        return {\"p_pos\": 0.5, \"bucket\": \"Neutral\", \"p_pos_llm\": 0.5, \"p_pos_hf\": 0.33, \"p_neg_hf\": 0.33}\n",
    "\n",
    "    p_pos_llm = gemma_score_01(text_clean)\n",
    "    hf = roberta_probs(text_clean)\n",
    "    p_pos_hf, p_neg_hf = hf[\"pos\"], hf[\"neg\"]\n",
    "\n",
    "    w_llm, w_hf = 0.4, 0.6\n",
    "    p_pos = w_llm * p_pos_llm + w_hf * p_pos_hf\n",
    "\n",
    "    if p_neg_hf - p_pos_hf > 0.20 and p_pos > 0.3:\n",
    "        p_pos -= 0.20\n",
    "\n",
    "    p_pos = float(np.clip(p_pos, 0.0, 1.0))\n",
    "    bucket = bucket_from_p(p_pos)\n",
    "    return {\n",
    "        \"p_pos\": p_pos,\n",
    "        \"bucket\": bucket,\n",
    "        \"p_pos_llm\": p_pos_llm,\n",
    "        \"p_pos_hf\": p_pos_hf,\n",
    "        \"p_neg_hf\": p_neg_hf,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Likes Weighting\n",
    "# -----------------------------\n",
    "def like_weight(likes: float) -> float:\n",
    "    if likes is None or likes <= 0:\n",
    "        return 1.0\n",
    "    if likes < 10:\n",
    "        return 1.2\n",
    "    if likes < 100:\n",
    "        return 2.0\n",
    "    if likes < 500:\n",
    "        return 3.0\n",
    "    return 4.0\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Improved Guest Extraction\n",
    "# -----------------------------\n",
    "\n",
    "BANNED_GUEST_WORDS = {\n",
    "    \"jesus\", \"praise jesus\", \"ohhhh\", \"video\", \"motivation\", \"johari\", \"topic\", \"content\"\n",
    "}\n",
    "\n",
    "GUEST_HINTS = re.compile(r\"(with|feat\\.|featuring|guest|bring back|have .* on|invite|episode with)\", re.I)\n",
    "TITLE_CUE_RE = re.compile(r\"feat\\.|featuring|with|guest|w/\", re.I)\n",
    "\n",
    "def extract_guests(text: str, video_title: str = \"\") -> list:\n",
    "    \"\"\"\n",
    "    Extract guest names from comment or title with 3-layer logic:\n",
    "    1. spaCy PERSON entities (fast)\n",
    "    2. Gemma (if hints present)\n",
    "    3. Fallback to video title if contains 'feat.' etc.\n",
    "    \"\"\"\n",
    "    text = clean_comment(text)\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    doc = nlp(text)\n",
    "    names = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "    # If found via spaCy, trust them (light clean)\n",
    "    if names:\n",
    "        names = [n for n in names if len(n) > 2 and n.lower() not in BANNED_GUEST_WORDS]\n",
    "        return list(set(names))\n",
    "\n",
    "    # Only call LLM if hints present\n",
    "    if not GUEST_HINTS.search(text):\n",
    "        return []\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract only the names of people explicitly mentioned or suggested as podcast guests.\n",
    "    Ignore general words, religious figures, or vague text.\n",
    "    Return only JSON array of proper names (no duplicates, no empty values).\n",
    "    Example:\n",
    "    [\"Jordan Peterson\", \"Dr K\", \"Alex O'Connor\"]\n",
    "    Comment: \"{text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = ollama.chat(model=\"gemma:2b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        names = json.loads(resp[\"message\"][\"content\"])\n",
    "    except Exception:\n",
    "        names = []\n",
    "\n",
    "    # Post-filter\n",
    "    if isinstance(names, list):\n",
    "        names = [\n",
    "            n.strip() for n in names\n",
    "            if n and len(n) > 2 and n[0].isupper() and n.lower() not in BANNED_GUEST_WORDS\n",
    "        ]\n",
    "    else:\n",
    "        names = []\n",
    "\n",
    "    # Fallback from video title\n",
    "    if not names and TITLE_CUE_RE.search(video_title):\n",
    "        doc_t = nlp(video_title)\n",
    "        title_names = [ent.text.strip() for ent in doc_t.ents if ent.label_ == \"PERSON\"]\n",
    "        names.extend(title_names)\n",
    "\n",
    "    return list(set(names))\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Topic Request Extraction\n",
    "# -----------------------------\n",
    "TOPIC_HINTS = re.compile(r\"(talk about|episode on|discuss|cover|would love|should do|next guest|topic|content about)\", re.I)\n",
    "\n",
    "def extract_topics(text: str) -> list:\n",
    "    text = clean_comment(text)\n",
    "    if not text or not TOPIC_HINTS.search(text):\n",
    "        return []\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract specific topic requests or subjects mentioned in this YouTube comment.\n",
    "    Return only JSON list of short topics.\n",
    "    Example: [\"AI\", \"mental health\", \"fitness\"]\n",
    "    Comment: \"{text}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = ollama.chat(model=\"gemma:2b\", messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "        topics = json.loads(resp[\"message\"][\"content\"])\n",
    "        if isinstance(topics, list):\n",
    "            return topics\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Apply All to DataFrame\n",
    "# -----------------------------\n",
    "def apply_sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"cleaned_text\"] = df[\"cleaned_text\"].fillna(\"\").astype(str)\n",
    "\n",
    "    # Sentiment\n",
    "    res = df[\"cleaned_text\"].progress_apply(ensemble_sentiment)\n",
    "    df[\"sentiment_p_pos\"] = res.apply(lambda r: r[\"p_pos\"])\n",
    "    df[\"sentiment_bucket\"] = res.apply(lambda r: r[\"bucket\"])\n",
    "    df[\"p_pos_llm\"] = res.apply(lambda r: r[\"p_pos_llm\"])\n",
    "    df[\"p_pos_hf\"] = res.apply(lambda r: r[\"p_pos_hf\"])\n",
    "    df[\"p_neg_hf\"] = res.apply(lambda r: r[\"p_neg_hf\"])\n",
    "\n",
    "    # Weights\n",
    "    df[\"comment_like_count\"] = df[\"comment_like_count\"].fillna(0).astype(int)\n",
    "    df[\"comment_weight\"] = df[\"comment_like_count\"].apply(like_weight)\n",
    "    df[\"impact_weighted_sentiment\"] = df[\"sentiment_p_pos\"] * df[\"comment_weight\"]\n",
    "\n",
    "    # New columns ‚Äî guests & topics\n",
    "    df[\"guest_mentions\"] = df.progress_apply(\n",
    "        lambda r: extract_guests(r[\"cleaned_text\"], r.get(\"video_title\", \"\")), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"topic_requests\"] = df[\"cleaned_text\"].progress_apply(extract_topics)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac05a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1296/1296 [08:52<00:00,  2.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1296/1296 [02:07<00:00, 10.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1296/1296 [00:44<00:00, 28.94it/s] \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) Run\n",
    "# -----------------------------\n",
    "df_sent = apply_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500064be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_p_pos</th>\n",
       "      <th>sentiment_bucket</th>\n",
       "      <th>p_pos_llm</th>\n",
       "      <th>p_pos_hf</th>\n",
       "      <th>p_neg_hf</th>\n",
       "      <th>comment_like_count</th>\n",
       "      <th>comment_weight</th>\n",
       "      <th>impact_weighted_sentiment</th>\n",
       "      <th>guest_mentions</th>\n",
       "      <th>topic_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like this format much better than the other ...</td>\n",
       "      <td>i like this format much better than the other ...</td>\n",
       "      <td>0.848971</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.901619</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.018766</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, this format is great. Except that one ti...</td>\n",
       "      <td>yeah, this format is great. except that one ti...</td>\n",
       "      <td>0.174155</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.123592</td>\n",
       "      <td>0.595837</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.208986</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes Praise Jesus Christ!</td>\n",
       "      <td>yes praise jesus christ!</td>\n",
       "      <td>0.892407</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.970679</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.070889</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@Little_Shadow_ Which episode was that one pl...</td>\n",
       "      <td>@ which episode was that one please?!?</td>\n",
       "      <td>0.411350</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.105584</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411350</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bro you should have invited a Muslim like Musl...</td>\n",
       "      <td>bro you should have invited a muslim like musl...</td>\n",
       "      <td>0.178369</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.037282</td>\n",
       "      <td>0.241366</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.214043</td>\n",
       "      <td>[muhammad ali]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üíõüíõüëä</td>\n",
       "      <td></td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I like the format but man‚Ä¶ while I usually dig...</td>\n",
       "      <td>i like the format but man while i usually dig ...</td>\n",
       "      <td>0.280766</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.775083</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.336919</td>\n",
       "      <td>[dr k]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I really want a conversation with Esther Perel...</td>\n",
       "      <td>i really want a conversation with esther perel...</td>\n",
       "      <td>0.486593</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.327655</td>\n",
       "      <td>0.056819</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.583912</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You need to have Britt Hartley on</td>\n",
       "      <td>you need to have britt hartley on</td>\n",
       "      <td>0.423873</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.099788</td>\n",
       "      <td>0.073581</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.508647</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Invite Omar Suleiman from Yaqeen Institute, he...</td>\n",
       "      <td>invite omar suleiman from yaqeen institute, he...</td>\n",
       "      <td>0.881981</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.929968</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881981</td>\n",
       "      <td>[omar suleiman]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Did you ever thought about looking into Islam ...</td>\n",
       "      <td>did you ever thought about looking into islam ...</td>\n",
       "      <td>0.509197</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.335329</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.611037</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We Love this shit man!</td>\n",
       "      <td>we love this shit man!</td>\n",
       "      <td>0.722093</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.870155</td>\n",
       "      <td>0.056719</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722093</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Very western centric lense</td>\n",
       "      <td>very western centric lense</td>\n",
       "      <td>0.350815</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.084692</td>\n",
       "      <td>0.158017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.420978</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Love them</td>\n",
       "      <td>love them</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.914291</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This was great to watch</td>\n",
       "      <td>this was great to watch</td>\n",
       "      <td>0.789711</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.982852</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.789711</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>YESSSSSSSS‚Äã@@danicapaulos2347</td>\n",
       "      <td>yessssssss@</td>\n",
       "      <td>0.712955</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.688259</td>\n",
       "      <td>0.027147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712955</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Debates are always better than a 1 on 1 convo.</td>\n",
       "      <td>debates are always better than a 1 on 1 convo.</td>\n",
       "      <td>0.632066</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.720110</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What I *dont* like is having to skip the first...</td>\n",
       "      <td>what i *dont* like is having to skip the first...</td>\n",
       "      <td>0.294991</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.880741</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294991</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This was a very stvpid and uninformed conversa...</td>\n",
       "      <td>this was a very stvpid and uninformed conversa...</td>\n",
       "      <td>0.257706</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.901869</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.309247</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>‚Äã@@Little_Shadow_Please reconsider how you are...</td>\n",
       "      <td>@ reconsider how you are presenting your opini...</td>\n",
       "      <td>0.265581</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>0.692963</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.265581</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>‚Å†@@Little_Shadow_has been since episode two.</td>\n",
       "      <td>@ been since episode two.</td>\n",
       "      <td>0.313246</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.105410</td>\n",
       "      <td>0.019464</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.375895</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LOVE THEM</td>\n",
       "      <td>love them</td>\n",
       "      <td>0.858574</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.914291</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858574</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The format is great! The guest‚Ä¶ please please ...</td>\n",
       "      <td>the format is great! the guest please please d...</td>\n",
       "      <td>0.826479</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.857465</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826479</td>\n",
       "      <td>[alex arguing]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>religion wont bring you purpose knowing there ...</td>\n",
       "      <td>religion wont bring you purpose knowing there ...</td>\n",
       "      <td>0.101042</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.757263</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101042</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The choice of people, the forms of respect and...</td>\n",
       "      <td>the choice of people, the forms of respect and...</td>\n",
       "      <td>0.727774</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.879623</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727774</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Yes! Fantastic format love Dr Ks instinct to r...</td>\n",
       "      <td>yes! fantastic format love dr ks instinct to r...</td>\n",
       "      <td>0.931055</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.968425</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931055</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.548041</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.480068</td>\n",
       "      <td>0.102255</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.548041</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>More of this please ‚ù§</td>\n",
       "      <td>more of this please</td>\n",
       "      <td>0.731317</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.635529</td>\n",
       "      <td>0.065384</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731317</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I've been subscribed and listening to your pod...</td>\n",
       "      <td>i've been subscribed and listening to your pod...</td>\n",
       "      <td>0.959141</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959141</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Keep this upüëçüèæüôèüèΩ</td>\n",
       "      <td>keep this up</td>\n",
       "      <td>0.521603</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.369339</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521603</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Yes, love it. It is very importance to show th...</td>\n",
       "      <td>yes, love it. it is very importance to show th...</td>\n",
       "      <td>0.811757</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.936261</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811757</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>These are missing in the world, these are the ...</td>\n",
       "      <td>these are missing in the world, these are the ...</td>\n",
       "      <td>0.170617</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>0.361134</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.170617</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dr Ben K is right but Jesus is still the most ...</td>\n",
       "      <td>dr ben k is right but jesus is still the most ...</td>\n",
       "      <td>0.515747</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.342911</td>\n",
       "      <td>0.075077</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515747</td>\n",
       "      <td>[dr ben k]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>THIS is so compelling. Thank you Stephen‚Ä¶</td>\n",
       "      <td>this is so compelling. thank you stephen</td>\n",
       "      <td>0.787048</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.978414</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787048</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohhhh I can‚Äôt wait to listen to this one! Love...</td>\n",
       "      <td>ohhhh i cant wait to listen to this one! love ...</td>\n",
       "      <td>0.924465</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924465</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text  \\\n",
       "0   I like this format much better than the other ...   \n",
       "1   Yeah, this format is great. Except that one ti...   \n",
       "2                            Yes Praise Jesus Christ!   \n",
       "3   @@Little_Shadow_ Which episode was that one pl...   \n",
       "4   Bro you should have invited a Muslim like Musl...   \n",
       "5                                                 üíõüíõüëä   \n",
       "6   I like the format but man‚Ä¶ while I usually dig...   \n",
       "7   I really want a conversation with Esther Perel...   \n",
       "8                   You need to have Britt Hartley on   \n",
       "9   Invite Omar Suleiman from Yaqeen Institute, he...   \n",
       "10  Did you ever thought about looking into Islam ...   \n",
       "11                             We Love this shit man!   \n",
       "12                         Very western centric lense   \n",
       "13                                          Love them   \n",
       "14                            This was great to watch   \n",
       "15                      YESSSSSSSS‚Äã@@danicapaulos2347   \n",
       "16     Debates are always better than a 1 on 1 convo.   \n",
       "17  What I *dont* like is having to skip the first...   \n",
       "18  This was a very stvpid and uninformed conversa...   \n",
       "19  ‚Äã@@Little_Shadow_Please reconsider how you are...   \n",
       "20       ‚Å†@@Little_Shadow_has been since episode two.   \n",
       "21                                          LOVE THEM   \n",
       "22  The format is great! The guest‚Ä¶ please please ...   \n",
       "23  religion wont bring you purpose knowing there ...   \n",
       "24  The choice of people, the forms of respect and...   \n",
       "25  Yes! Fantastic format love Dr Ks instinct to r...   \n",
       "26                                                Yes   \n",
       "27                              More of this please ‚ù§   \n",
       "28  I've been subscribed and listening to your pod...   \n",
       "29                                   Keep this upüëçüèæüôèüèΩ   \n",
       "30  Yes, love it. It is very importance to show th...   \n",
       "31  These are missing in the world, these are the ...   \n",
       "32  Dr Ben K is right but Jesus is still the most ...   \n",
       "33          THIS is so compelling. Thank you Stephen‚Ä¶   \n",
       "34  Ohhhh I can‚Äôt wait to listen to this one! Love...   \n",
       "\n",
       "                                         cleaned_text  sentiment_p_pos  \\\n",
       "0   i like this format much better than the other ...         0.848971   \n",
       "1   yeah, this format is great. except that one ti...         0.174155   \n",
       "2                            yes praise jesus christ!         0.892407   \n",
       "3              @ which episode was that one please?!?         0.411350   \n",
       "4   bro you should have invited a muslim like musl...         0.178369   \n",
       "5                                                             0.500000   \n",
       "6   i like the format but man while i usually dig ...         0.280766   \n",
       "7   i really want a conversation with esther perel...         0.486593   \n",
       "8                   you need to have britt hartley on         0.423873   \n",
       "9   invite omar suleiman from yaqeen institute, he...         0.881981   \n",
       "10  did you ever thought about looking into islam ...         0.509197   \n",
       "11                             we love this shit man!         0.722093   \n",
       "12                         very western centric lense         0.350815   \n",
       "13                                          love them         0.886574   \n",
       "14                            this was great to watch         0.789711   \n",
       "15                                        yessssssss@         0.712955   \n",
       "16     debates are always better than a 1 on 1 convo.         0.632066   \n",
       "17  what i *dont* like is having to skip the first...         0.294991   \n",
       "18  this was a very stvpid and uninformed conversa...         0.257706   \n",
       "19  @ reconsider how you are presenting your opini...         0.265581   \n",
       "20                          @ been since episode two.         0.313246   \n",
       "21                                          love them         0.858574   \n",
       "22  the format is great! the guest please please d...         0.826479   \n",
       "23  religion wont bring you purpose knowing there ...         0.101042   \n",
       "24  the choice of people, the forms of respect and...         0.727774   \n",
       "25  yes! fantastic format love dr ks instinct to r...         0.931055   \n",
       "26                                                yes         0.548041   \n",
       "27                                more of this please         0.731317   \n",
       "28  i've been subscribed and listening to your pod...         0.959141   \n",
       "29                                       keep this up         0.521603   \n",
       "30  yes, love it. it is very importance to show th...         0.811757   \n",
       "31  these are missing in the world, these are the ...         0.170617   \n",
       "32  dr ben k is right but jesus is still the most ...         0.515747   \n",
       "33           this is so compelling. thank you stephen         0.787048   \n",
       "34  ohhhh i cant wait to listen to this one! love ...         0.924465   \n",
       "\n",
       "   sentiment_bucket  p_pos_llm  p_pos_hf  p_neg_hf  comment_like_count  \\\n",
       "0          Positive      0.770  0.901619  0.010586                   6   \n",
       "1          Negative      0.750  0.123592  0.595837                   4   \n",
       "2          Positive      0.775  0.970679  0.003459                   2   \n",
       "3           Neutral      0.870  0.105584  0.015177                   0   \n",
       "4          Negative      0.890  0.037282  0.241366                   2   \n",
       "5           Neutral      0.500  0.330000  0.330000                   0   \n",
       "6          Negative      0.675  0.017943  0.775083                   1   \n",
       "7           Neutral      0.725  0.327655  0.056819                   1   \n",
       "8           Neutral      0.910  0.099788  0.073581                   2   \n",
       "9          Positive      0.810  0.929968  0.007452                   0   \n",
       "10          Neutral      0.770  0.335329  0.015801                   1   \n",
       "11         Positive      0.500  0.870155  0.056719                   0   \n",
       "12          Neutral      0.750  0.084692  0.158017                   2   \n",
       "13         Positive      0.845  0.914291  0.012388                   0   \n",
       "14         Positive      0.500  0.982852  0.003657                   0   \n",
       "15         Positive      0.750  0.688259  0.027147                   0   \n",
       "16          Neutral      0.500  0.720110  0.019981                   0   \n",
       "17         Negative      0.725  0.008319  0.880741                   0   \n",
       "18         Negative      0.635  0.006177  0.901869                   1   \n",
       "19         Negative      0.650  0.009301  0.692963                   0   \n",
       "20         Negative      0.625  0.105410  0.019464                   1   \n",
       "21         Positive      0.775  0.914291  0.012388                   0   \n",
       "22         Positive      0.780  0.857465  0.020275                   0   \n",
       "23         Negative      0.725  0.018403  0.757263                   0   \n",
       "24         Positive      0.500  0.879623  0.013804                   0   \n",
       "25         Positive      0.875  0.968425  0.003735                   0   \n",
       "26          Neutral      0.650  0.480068  0.102255                   0   \n",
       "27         Positive      0.875  0.635529  0.065384                   0   \n",
       "28         Positive      0.920  0.985235  0.002860                   0   \n",
       "29          Neutral      0.750  0.369339  0.039414                   0   \n",
       "30         Positive      0.625  0.936261  0.009100                   0   \n",
       "31         Negative      0.810  0.077694  0.361134                   0   \n",
       "32          Neutral      0.775  0.342911  0.075077                   0   \n",
       "33         Positive      0.500  0.978414  0.005468                   0   \n",
       "34         Positive      0.830  0.987442  0.003022                   0   \n",
       "\n",
       "    comment_weight  impact_weighted_sentiment   guest_mentions topic_requests  \n",
       "0              1.2                   1.018766               []             []  \n",
       "1              1.2                   0.208986               []             []  \n",
       "2              1.2                   1.070889               []             []  \n",
       "3              1.0                   0.411350               []             []  \n",
       "4              1.2                   0.214043   [muhammad ali]             []  \n",
       "5              1.0                   0.500000               []             []  \n",
       "6              1.2                   0.336919           [dr k]             []  \n",
       "7              1.2                   0.583912               []             []  \n",
       "8              1.2                   0.508647               []             []  \n",
       "9              1.0                   0.881981  [omar suleiman]             []  \n",
       "10             1.2                   0.611037               []             []  \n",
       "11             1.0                   0.722093               []             []  \n",
       "12             1.2                   0.420978               []             []  \n",
       "13             1.0                   0.886574               []             []  \n",
       "14             1.0                   0.789711               []             []  \n",
       "15             1.0                   0.712955               []             []  \n",
       "16             1.0                   0.632066               []             []  \n",
       "17             1.0                   0.294991               []             []  \n",
       "18             1.2                   0.309247               []             []  \n",
       "19             1.0                   0.265581               []             []  \n",
       "20             1.2                   0.375895               []             []  \n",
       "21             1.0                   0.858574               []             []  \n",
       "22             1.0                   0.826479   [alex arguing]             []  \n",
       "23             1.0                   0.101042               []             []  \n",
       "24             1.0                   0.727774               []             []  \n",
       "25             1.0                   0.931055               []             []  \n",
       "26             1.0                   0.548041               []             []  \n",
       "27             1.0                   0.731317               []             []  \n",
       "28             1.0                   0.959141               []             []  \n",
       "29             1.0                   0.521603               []             []  \n",
       "30             1.0                   0.811757               []             []  \n",
       "31             1.0                   0.170617               []             []  \n",
       "32             1.0                   0.515747       [dr ben k]             []  \n",
       "33             1.0                   0.787048               []             []  \n",
       "34             1.0                   0.924465               []             []  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent[[\n",
    "    \"comment_text\",\n",
    "    \"cleaned_text\",\n",
    "    \"sentiment_p_pos\",\n",
    "    \"sentiment_bucket\",\n",
    "    \"p_pos_llm\",\n",
    "    \"p_pos_hf\",\n",
    "    \"p_neg_hf\",\n",
    "    \"comment_like_count\",\n",
    "    \"comment_weight\",\n",
    "    \"impact_weighted_sentiment\",\n",
    "    \"guest_mentions\",\n",
    "    \"topic_requests\"\n",
    "]].head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d6f3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_bucket\n",
       "Negative    728\n",
       "Positive    319\n",
       "Neutral     249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent['sentiment_bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec65355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guest_mentions\n",
       "[]                                                                             1001\n",
       "[alex]                                                                           55\n",
       "[dr k]                                                                           32\n",
       "[god]                                                                            26\n",
       "[dr k, alex]                                                                     12\n",
       "[jesus christ]                                                                    9\n",
       "[alex o'connor]                                                                   7\n",
       "[dr.]                                                                             6\n",
       "[sandra ann shaw]                                                                 5\n",
       "[jordan peterson]                                                                 5\n",
       "[Jordan Peterson, Dr K, Alex O'Connor]                                            3\n",
       "[muhammad ali]                                                                    3\n",
       "[dr k, alex o'connor]                                                             3\n",
       "[dr k together, alex]                                                             2\n",
       "[john 14:6]                                                                       2\n",
       "[paul]                                                                            2\n",
       "[steve]                                                                           2\n",
       "[john]                                                                            2\n",
       "[john vervaeke]                                                                   2\n",
       "[alex arguing]                                                                    2\n",
       "[omar suleiman]                                                                   2\n",
       "[iam come]                                                                        1\n",
       "[naoki urasawa]                                                                   1\n",
       "[a.i]                                                                             1\n",
       "[john 5:19]                                                                       1\n",
       "[chris]                                                                           1\n",
       "[bruce greyson, jeffrey long\\ndr]                                                 1\n",
       "[uhh dr]                                                                          1\n",
       "[thou labour]                                                                     1\n",
       "[john 15:13, god]                                                                 1\n",
       "[sam harris]                                                                      1\n",
       "[charlie kirk]                                                                    1\n",
       "[david]                                                                           1\n",
       "[alex christian]                                                                  1\n",
       "[jonathan pageau]                                                                 1\n",
       "[dr., koukl, alex]                                                                1\n",
       "[dr jbp]                                                                          1\n",
       "[plus jesus]                                                                      1\n",
       "[alex occonor]                                                                    1\n",
       "[jesus christ, john]                                                              1\n",
       "[lilith]                                                                          1\n",
       "[omg o'connor and dr k]                                                           1\n",
       "[bill carson]                                                                     1\n",
       "[richard dawkins, sam harris]                                                     1\n",
       "[paul, albert mohler]                                                             1\n",
       "[david r. hawkins]                                                                1\n",
       "[matthew 10:16, matthew 26:52, john 18:36]                                        1\n",
       "[hey dr k]                                                                        1\n",
       "[nouman, ali khan]                                                                1\n",
       "[bob cornuke]                                                                     1\n",
       "[david ghiyam  kaballah]                                                          1\n",
       "[alok kanojia]                                                                    1\n",
       "[bruce banner, dr k, alex]                                                        1\n",
       "[channel5]                                                                        1\n",
       "[alex, nah]                                                                       1\n",
       "[johnny chang]                                                                    1\n",
       "[ali khan]                                                                        1\n",
       "[neil]                                                                            1\n",
       "[pride]                                                                           1\n",
       "[bible, jesus himself, god]                                                       1\n",
       "[lee]                                                                             1\n",
       "[james webb telescope]                                                            1\n",
       "[alex clarifies]                                                                  1\n",
       "[dr k, alex o]                                                                    1\n",
       "[destroy alex, wes huff]                                                          1\n",
       "[dr k's, alex o'connor, dr peterson's, dr k, jordan peterson]                     1\n",
       "[alex 10/10]                                                                      1\n",
       "[roger seheult]                                                                   1\n",
       "[god jesus]                                                                       1\n",
       "[dr k. they]                                                                      1\n",
       "[jesus taught, matthew 6:10, jesus death]                                         1\n",
       "[smart alex]                                                                      1\n",
       "[kevin  zadai]                                                                    1\n",
       "[peterson, alex]                                                                  1\n",
       "[peterson]                                                                        1\n",
       "[christopher hitchens]                                                            1\n",
       "[bob adamson]                                                                     1\n",
       "[greg]                                                                            1\n",
       "[ms.sandra ann shaw, god]                                                         1\n",
       "[sandra]                                                                          1\n",
       "[sandra ann shaw  mentioned]                                                      1\n",
       "[woman(sandra ann shaw]                                                           1\n",
       "[sandra ann]                                                                      1\n",
       "[alex starts]                                                                     1\n",
       "[joseph, apostle paul, david]                                                     1\n",
       "[zoomer]                                                                          1\n",
       "[alex 1 to 1 more, sanatan dharma]                                                1\n",
       "[alex mentions]                                                                   1\n",
       "[dr. robert sapolsky]                                                             1\n",
       "[las lajas, roman catholic]                                                       1\n",
       "[dr k. as, alex o'connor]                                                         1\n",
       "[robin dunbar]                                                                    1\n",
       "[steven]                                                                          1\n",
       "[alex o']                                                                         1\n",
       "[alex o]                                                                          1\n",
       "[demikianlah  indahnya perbedaan, meskipun melelahkan, bahas topik masalah]       1\n",
       "[dr frank turek]                                                                  1\n",
       "[kevin smith]                                                                     1\n",
       "[greg, dr k, alex]                                                                1\n",
       "[hahahaha knot]                                                                   1\n",
       "[video.i, motivation.when]                                                        1\n",
       "[jonathan pageau, jordan hall, alex]                                              1\n",
       "[james white]                                                                     1\n",
       "[dr ben k]                                                                        1\n",
       "[sandra ann shaw, god]                                                            1\n",
       "[jesus loved]                                                                     1\n",
       "[emoji]                                                                           1\n",
       "[alex o'connor's]                                                                 1\n",
       "[plato, isaac newton]                                                             1\n",
       "[alex voted]                                                                      1\n",
       "[-israel, israel_usa, lim_0->)0=0]                                                1\n",
       "[jordan peterson, alex]                                                           1\n",
       "[robert sapolsky]                                                                 1\n",
       "[yo dr k]                                                                         1\n",
       "[alex oconnor]                                                                    1\n",
       "[omfg alex]                                                                       1\n",
       "[dr., rena, alex]                                                                 1\n",
       "[steven, dr k's]                                                                  1\n",
       "[gabor]                                                                           1\n",
       "[dr k, dr k's, alex]                                                              1\n",
       "[dr  k, alex]                                                                     1\n",
       "[alex cares, dr., alex]                                                           1\n",
       "[dr k. talks, dr k, alex]                                                         1\n",
       "[dr k absolutely nailed, dr k, alex]                                              1\n",
       "[john lennox]                                                                     1\n",
       "[dr. k.]                                                                          1\n",
       "[sisyphus]                                                                        1\n",
       "[47:30 alex]                                                                      1\n",
       "[alex - its]                                                                      1\n",
       "[jesus taught]                                                                    1\n",
       "[alex o'connors]                                                                  1\n",
       "[alex talking, dr k]                                                              1\n",
       "[meet dr k]                                                                       1\n",
       "[hahaha watangirwa]                                                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent['guest_mentions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3946ac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_requests\n",
       "[]    1296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent['topic_requests'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41fdd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sent.to_csv('/Users/riadanas/Desktop/MLE Diary of a CEO/data/processed/processed_snapshot4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6a907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-diary-of-a-ceo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
